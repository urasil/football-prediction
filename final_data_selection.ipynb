{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d077fe24",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648e008",
   "metadata": {},
   "source": [
    "First, we will load the data into our DataFrame. Sort by date and denote which Season each match corresponds to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0db36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"finalData.csv\"\n",
    "df = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns\n",
    "df.columns = ['Date', 'Home Team', 'Away Team', 'Full Time Home Goals', 'Full Time Away Goals', 'Full Time Result',       \n",
    "'Half Time Home Goals', 'Half Time Away Goals', 'Half Time Result', 'Referee', 'Home Shots', 'Away Shots', 'Home Shots on Target',   \n",
    "'Away Shots on Target', 'Home Corners', 'Away Corners', 'Home Fouls', 'Away Fouls', 'Home Yellow Cards', 'Away Yellow Cards',     \n",
    "'Home Red Cards', 'Away Red Cards', 'Home Possession', 'Away Possession', 'Home Passes Completed', 'Home Passes PCT',\n",
    "'Home Progressive Passes', 'Home Progressive Passing Distance', 'Home xG', 'Home Take Ons Won', 'Home Take Ons', \n",
    "'Home Interceptions', 'Home Blocks', 'Home Touches', 'Home Touches Def 3rd', 'Home Touches Mid 3rd', 'Home Touches Att 3rd',\n",
    "'Home Carries', 'Home Carries Progressive Distance', 'Home Tackles', 'Home Tackles Won', 'Away Passes Completed',\n",
    "'Away Passes PCT', 'Away Progressive Passes', 'Away Progressive Passing Distance', 'Away xG',\n",
    "'Away Take Ons Won', 'Away Take Ons', 'Away Interceptions', 'Away Blocks', 'Away Touches', 'Away Touches Def 3rd',\n",
    "'Away Touches Mid 3rd', 'Away Touches Att 3rd', 'Away Carries', 'Away Carries Progressive Distance', 'Away Tackles',\n",
    "'Away Tackles Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2eba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure sorted by date\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# each season starts at 08 and ends at 05 of next year - 2000-2001 season will be the 2000 season\n",
    "def get_season(date):\n",
    "    if date.month >= 8:  \n",
    "        return (date.year)\n",
    "    else:  \n",
    "        return (date.year - 1)\n",
    "\n",
    "df['Season'] = df['Date'].apply(get_season)\n",
    "df['Match Outcome'] = df['Full Time Result'].map({'H': 1, 'D': 0, 'A': -1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e15b1d",
   "metadata": {},
   "source": [
    "Here, we begin engineering new features. The following function enables us to find the previous matches a team played (within this or the previous season). Using this key function, we created several features:\n",
    "\n",
    "Average Goal Conversion Rate Difference, Average Attacking Intensity Difference, Average Disciplinary Pressure Difference, Recent Performances, Average Goals Scored Difference, Average Goals Conceded Difference, ...\n",
    "\n",
    "Note: All averages use the previous RECENCY_NUM matches. If the number of previous matches in this season is too few, it will draw from the previous season as well. \n",
    "\n",
    "Note 2: After feature engineering, we will have to remove 101 matches that do not have RECENCY_NUM=5 matches prior. Unfortunately, this will reduce our dataset by 3.66%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECENCY_NUM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Points = total points in the game. win:3, draw:1, loss:0... DROPPED AFTERWARDS\n",
    "# Total Points = cumulative sum of the team points, per team, per season\n",
    "# Point Difference = difference between total points of the teams, per match\n",
    "def calculate_season_points(df):\n",
    "    df['Home Team Points'] = 0\n",
    "    df['Away Team Points'] = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['Match Outcome'] == 1:  \n",
    "            df.at[idx, 'Home Team Points'] = 3\n",
    "            df.at[idx, 'Away Team Points'] = 0\n",
    "        elif row['Match Outcome'] == 0: \n",
    "            df.at[idx, 'Home Team Points'] = 1\n",
    "            df.at[idx, 'Away Team Points'] = 1\n",
    "        elif row['Match Outcome'] == -1:  \n",
    "            df.at[idx, 'Home Team Points'] = 0\n",
    "            df.at[idx, 'Away Team Points'] = 3\n",
    "\n",
    "    df['Home Total Seasonal Points'] = (df.groupby(['Home Team', 'Season'])['Home Team Points'].cumsum())\n",
    "    df['Away Total Seasonal Points'] = (df.groupby(['Away Team', 'Season'])['Away Team Points'].cumsum())\n",
    "    # df['Seasonal Point Difference'] = df['Home Total Seasonal Points'] - df['Away Total Seasonal Points']\n",
    "    # df.drop(columns=['Home Team Points', 'Away Team Points'], inplace=True)\n",
    "\n",
    "    return df\n",
    "df = calculate_season_points(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardisation(df, terms=['Difference Average Goals Scored Last X Games', 'Difference Average Goals Conceded Last X Games', 'Point Difference', 'xG Difference']):\n",
    "    scaler = StandardScaler()\n",
    "    df[terms] = scaler.fit_transform(df[terms])\n",
    "    return df\n",
    "\n",
    "# normalises a specific set of columns\n",
    "def normalisation(df, terms=['Difference Average Goals Scored Last X Games', 'Difference Average Goals Conceded Last X Games', 'Point Difference', 'xG Difference']):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[terms] = scaler.fit_transform(df[terms])\n",
    "    return df\n",
    "\n",
    "# label encoding - use for boosting models\n",
    "def label_encoding(df, col=['Home Team', 'Away Team'], dataframe=True):\n",
    "    label_encoder = LabelEncoder()\n",
    "    if dataframe:\n",
    "        for c in col:\n",
    "            df[c] = label_encoder.fit_transform(df[c])\n",
    "    else:\n",
    "        df = label_encoder.fit_transform(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a71c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pca(df):\n",
    "    # drop the irrelevant terms\n",
    "    featuresToDrop = ['Date', 'Home Team', 'Away Team', 'Full Time Result', 'Half Time Result', 'Referee']\n",
    "    assert set(featuresToDrop).issubset(df.columns), \"Some columns in featuresToDrop are missing in df\"\n",
    "    df2 = df.drop(featuresToDrop, axis=1)\n",
    "    \n",
    "    df2 = standardisation(df2, terms=list(df2.columns))\n",
    "    \n",
    "    pca = PCA()\n",
    "    pca_components = pca.fit_transform(df2)\n",
    "    \n",
    "    # find the explained variance ratio\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(\"Explained Variance Ratio: \", explained_variance)\n",
    "\n",
    "    # select number of components based on explained variance (e.g., 95% variance)\n",
    "    cumulative_variance = explained_variance.cumsum()\n",
    "    n_components = next(i for i, v in enumerate(cumulative_variance) if v >= 0.95) + 1\n",
    "    print(f\"Number of components to retain 95% variance: {n_components}\")\n",
    "\n",
    "    # visualize explained variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(cumulative_variance, marker='o', linestyle='--')\n",
    "    plt.title('Cumulative Explained Variance by Number of Components')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return n_components\n",
    "    \n",
    "number_of_components = pca(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddadc79",
   "metadata": {},
   "source": [
    "Next, we reduced the feature data set to 5 sections of inputs: Home Advantage, Attacking Strength, Midfield Strength, Defensive Strength, and extras. \n",
    "\n",
    "Discarded features include: \n",
    "\n",
    "'Half Time Home Goals', 'Half Time Away Goals', 'Half Time Result', 'Referee', 'Home Shots', 'Away Shots', 'Home Fouls', 'Away Fouls', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards', 'Home Possession', 'Away Possession', 'Home Progressive Passing Distance', 'Home xG', 'Home Take Ons', 'Home Touches', 'Home Touches Def 3rd', 'Home Carries Progressive Distance', 'Away Progressive Passing Distance', 'Away xG', 'Away Take Ons', 'Away Touches', 'Away Touches Def 3rd', 'Away Carries Progressive Distance', 'Season', 'Home Team Points', 'Away Team Points', 'Home Total Seasonal Points', 'Away Total Seasonal Points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # Home Advantage\n",
    "    \"Home Team\",\n",
    "    \"Away Team\",\n",
    "    \"Match Outcome\",\n",
    "    \"Full Time Home Goals\",\n",
    "    \"Full Time Away Goals\",\n",
    "    \n",
    "    # Attacking Strength\n",
    "    \"Home Shots on Target\", \"Away Shots on Target\",\n",
    "    \"Home Progressive Passes\", \"Away Progressive Passes\",\n",
    "    \"Home Touches Att 3rd\", \"Away Touches Att 3rd\",\n",
    "    \"Home Take Ons Won\", \"Away Take Ons Won\",\n",
    "    \"Home Corners\", \"Away Corners\",\n",
    "    \n",
    "    # Midfield Strength\n",
    "    \"Home Touches Mid 3rd\", \"Away Touches Mid 3rd\",\n",
    "    \"Home Passes Completed\", \"Away Passes Completed\",\n",
    "    \"Home Passes PCT\", \"Away Passes PCT\",\n",
    "    \"Home Carries\", \"Away Carries\",\n",
    "    \n",
    "    # Defensive Strength\n",
    "    \"Home Tackles\", \"Away Tackles\",\n",
    "    \"Home Tackles Won\", \"Away Tackles Won\",\n",
    "    \"Home Blocks\", \"Away Blocks\",\n",
    "    \"Home Interceptions\", \"Away Interceptions\",\n",
    "    \n",
    "    # Extra\n",
    "    \"Full Time Result\",\n",
    "    'Date'\n",
    "]\n",
    "\n",
    "new_df = df[features].copy()\n",
    "new_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def chi_square(df):\n",
    "    # organise dataset into X (training examples) and y (targets)\n",
    "    featuresToDrop = ['Date', 'Home Team', 'Full Time Result', 'Away Team', 'Match Outcome']\n",
    "    assert set(featuresToDrop).issubset(df.columns), \"Some columns in featuresToDrop are missing in df\"\n",
    "    data = df.drop(featuresToDrop, axis=1)\n",
    "    df['Match Outcome'] = df['Full Time Result'].map({'H': 1, 'D': 0, 'A': -1})\n",
    "    target = df['Match Outcome']\n",
    "    \n",
    "    # chi2 scoring function requires non-negative input: normalisation\n",
    "    data = normalisation(data, terms=list(data.columns))\n",
    "    \n",
    "    # collect the feature names\n",
    "    feature_names = list(data.columns)\n",
    "    \n",
    "    # perform chi square selection    \n",
    "    chi_select = SelectKBest(chi2, k=min(number_of_components, len(data.columns)))\n",
    "    new_data = chi_select.fit_transform(data, target)\n",
    "    \n",
    "    # collect features\n",
    "    selected_features = []\n",
    "    for i, b in enumerate(chi_select.get_support()):\n",
    "        if b:\n",
    "            selected_features.append(feature_names[i])\n",
    "    \n",
    "    # get the chi-square scores for all features\n",
    "    chi_scores = chi_select.scores_\n",
    "\n",
    "    # create a dataFrame for easy visualization\n",
    "    chi2_df = pd.DataFrame({'Feature': feature_names, 'Chi-Square Score': chi_scores})\n",
    "    chi2_df = chi2_df.sort_values(by='Chi-Square Score', ascending=False)\n",
    "\n",
    "    # plot the scores\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    colours = ['skyblue' if i < number_of_components else 'gray' for i in range(len(chi2_df))]\n",
    "    plt.barh(chi2_df['Feature'], chi2_df['Chi-Square Score'], color=colours)\n",
    "    plt.xlabel('Chi-Square Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature Importance (Chi-Square)')\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to show the highest scores at the top\n",
    "    plt.tight_layout()\n",
    "    plt.tick_params(axis=\"y\", pad=10, labelsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "    return chi2_df\n",
    "    \n",
    "chi2_df = chi_square(new_df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417a651",
   "metadata": {},
   "source": [
    "Now we will take the feature importance scores from the Chi-Square distribution and adjust the weights to approach a gradual steady decline. This will allow the less important features to contribute to our feature engineering later while preserving a hierarchical ranking. \n",
    "\n",
    "Note: the number 1/3 was chosen arbitrarily but it was observed to be a standard heuristic among Machine Learning papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e73e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def adjust_feature_weights(features, chi2_df):\n",
    "    # Aggregate Home and Away importance scores\n",
    "    aggregated_scores = {}\n",
    "    for feature_pair in features:\n",
    "        home_feature, away_feature = feature_pair\n",
    "        home_score = chi2_df.loc[chi2_df['Feature'] == home_feature, 'Chi-Square Score'].values[0]\n",
    "        away_score = chi2_df.loc[chi2_df['Feature'] == away_feature, 'Chi-Square Score'].values[0]\n",
    "        aggregated_scores[feature_pair] = home_score + away_score\n",
    "\n",
    "    # Sort features by aggregated importance\n",
    "    sorted_features = sorted(aggregated_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Adjust scores using the /3 rule\n",
    "    adjusted_scores = {}\n",
    "    adjusted_scores[sorted_features[0][0]] = sorted_features[0][1]  # Most important feature remains unchanged\n",
    "    \n",
    "    for i in range(1, len(sorted_features)):\n",
    "        current_feature, current_score = sorted_features[i]\n",
    "        previous_feature, previous_score = sorted_features[i - 1]\n",
    "        \n",
    "        if current_score < previous_score / 3:\n",
    "            current_score = previous_score / 3\n",
    "        adjusted_scores[current_feature] = current_score\n",
    "\n",
    "    # Assign adjusted scores equally to Home and Away features\n",
    "    final_weights = {}\n",
    "    for feature_pair, score in adjusted_scores.items():\n",
    "        home_feature, away_feature = feature_pair\n",
    "        final_weights[home_feature] = score / 2\n",
    "        final_weights[away_feature] = score / 2\n",
    "    \n",
    "    return final_weights\n",
    "\n",
    "def plot_adjusted_features(weights, title):\n",
    "    # prepare data for plotting\n",
    "    features = list(weights.keys())\n",
    "    importance = list(weights.values())\n",
    "\n",
    "    # create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colours = ['skyblue' if 'Home' in feature else 'lightcoral' for feature in features]\n",
    "    plt.barh(features, importance, color=colours)\n",
    "\n",
    "    # customize the plot\n",
    "    plt.xlabel('Adjusted Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()  # highest scores at the top\n",
    "    plt.tight_layout()\n",
    "    plt.tick_params(axis=\"y\", pad=5, labelsize=10)  # adjust y-axis label size for better visibility\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_strength_features_separate(df, chi2_df):\n",
    "    # Define feature pairs for each group\n",
    "    attack_features = [\n",
    "        (\"Home Shots on Target\", \"Away Shots on Target\"),\n",
    "        (\"Home Progressive Passes\", \"Away Progressive Passes\"),\n",
    "        (\"Home Touches Att 3rd\", \"Away Touches Att 3rd\"),\n",
    "        (\"Home Take Ons Won\", \"Away Take Ons Won\"),\n",
    "        (\"Home Corners\", \"Away Corners\")\n",
    "    ]\n",
    "    midfield_features = [\n",
    "        (\"Home Touches Mid 3rd\", \"Away Touches Mid 3rd\"),\n",
    "        (\"Home Passes Completed\", \"Away Passes Completed\"),\n",
    "        (\"Home Passes PCT\", \"Away Passes PCT\"),\n",
    "        (\"Home Carries\", \"Away Carries\")\n",
    "    ]\n",
    "    defense_features = [\n",
    "        (\"Home Tackles\", \"Away Tackles\"),\n",
    "        (\"Home Tackles Won\", \"Away Tackles Won\"),\n",
    "        (\"Home Blocks\", \"Away Blocks\"),\n",
    "        (\"Home Interceptions\", \"Away Interceptions\")\n",
    "    ]\n",
    "    \n",
    "    # Adjust weights for each group\n",
    "    attack_weights = adjust_feature_weights(attack_features, chi2_df)\n",
    "    midfield_weights = adjust_feature_weights(midfield_features, chi2_df)\n",
    "    defense_weights = adjust_feature_weights(defense_features, chi2_df)\n",
    "    \n",
    "    plot_adjusted_features(attack_weights, \"Attack Weights Adjusted Feature Importance\")\n",
    "    plot_adjusted_features(midfield_weights, \"Midfield Weights Adjusted Feature Importance\")\n",
    "    plot_adjusted_features(defense_weights, \"Defense Weights Adjusted Feature Importance\")\n",
    "    \n",
    "    # Calculate strength scores for Home and Away\n",
    "    def calculate_strength(feature_pairs, weights, team_type):\n",
    "        strength_score = 0\n",
    "        for home_feature, away_feature in feature_pairs:\n",
    "            feature = home_feature if team_type == \"Home\" else away_feature\n",
    "            strength_score += df[feature] * weights[feature]\n",
    "        return strength_score\n",
    "\n",
    "    # Compute Home and Away strengths for Attack, Midfield, and Defense\n",
    "    df['Home Attack Strength'] = calculate_strength(attack_features, attack_weights, \"Home\")\n",
    "    df['Away Attack Strength'] = calculate_strength(attack_features, attack_weights, \"Away\")\n",
    "    df['Home Midfield Strength'] = calculate_strength(midfield_features, midfield_weights, \"Home\")\n",
    "    df['Away Midfield Strength'] = calculate_strength(midfield_features, midfield_weights, \"Away\")\n",
    "    df['Home Defense Strength'] = calculate_strength(defense_features, defense_weights, \"Home\")\n",
    "    df['Away Defense Strength'] = calculate_strength(defense_features, defense_weights, \"Away\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "strength_df = create_strength_features_separate(new_df, chi2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b2571",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def avg_stats_last_x_games(df):\n",
    "    \n",
    "    def calculate_running_avg(stats_list, x):\n",
    "        if len(stats_list) < x:\n",
    "            return None\n",
    "        return sum(stats_list[-x:]) / x\n",
    "\n",
    "    metrics = ['Goals Scored', 'Goals Conceded', 'Attack Strength', 'Midfield Strength', 'Defense Strength', 'Recent Performance']# , 'xG', 'Disciplinary Pressure']\n",
    "    for metric in metrics:\n",
    "        for x in range(1, RECENCY_NUM + 1):\n",
    "            df[f'Avg {metric} Home Last {x} Games'] = None\n",
    "            df[f'Avg {metric} Away Last {x} Games'] = None\n",
    "    running_stats = {}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        for team_type in ['Home Team', 'Away Team']:\n",
    "            team = row[team_type]\n",
    "            stat_type = team_type.split()[0]  # Home or Away\n",
    "\n",
    "            if team not in running_stats:\n",
    "                running_stats[team] = {\n",
    "                    'Goals Scored': [],\n",
    "                    'Goals Conceded': [],\n",
    "                    'Attack Strength': [],\n",
    "                    'Midfield Strength': [],\n",
    "                    'Defense Strength': [],\n",
    "                    #'Disciplinary Pressure': [],\n",
    "                    'Recent Performance': []\n",
    "                }\n",
    "\n",
    "            team_stats = running_stats[team]\n",
    "\n",
    "            for x in range(1, RECENCY_NUM + 1):\n",
    "                for metric in metrics:\n",
    "                    avg_stat = calculate_running_avg(team_stats[metric], x)\n",
    "                    df.at[idx, f'Avg {metric} {stat_type} Last {x} Games'] = avg_stat\n",
    "            team_stats['Goals Scored'].append(row['Full Time Home Goals'] if stat_type == 'Home' else row['Full Time Away Goals'])\n",
    "            team_stats['Goals Conceded'].append(row['Full Time Away Goals'] if stat_type == 'Home' else row['Full Time Home Goals'])\n",
    "            team_stats['Attack Strength'].append(row['Home Attack Strength'] if stat_type == 'Home' else row['Away Attack Strength'])\n",
    "            team_stats['Midfield Strength'].append(row['Home Midfield Strength'] if stat_type == 'Home' else row['Away Midfield Strength'])\n",
    "            team_stats['Defense Strength'].append(row['Home Defense Strength'] if stat_type == 'Home' else row['Away Defense Strength'])\n",
    "            #team_stats['xG'].append(row['xG Home'] if stat_type == 'Home' else row['xG Away'])\n",
    "            #team_stats['Disciplinary Pressure'].append(row['Home Disciplinary Pressure'] if stat_type == 'Home' else row['Away Disciplinary Pressure'])\n",
    "            team_stats['Recent Performance'].append(1 if (row['Full Time Result'] == 'H' and stat_type == 'Home') or (row['Full Time Result'] == 'A' and stat_type == 'Away') else 0.5 if row['Full Time Result'] == 'D' else 0)\n",
    "    return df\n",
    "\n",
    "df = avg_stats_last_x_games(strength_df)\n",
    "df.dropna(inplace=True)    # removes the matches without enough X previous data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1192d",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac319aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None): \n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a433c3f",
   "metadata": {},
   "source": [
    "The first method of feature selection that we will look at is Recursive Feature Engineering. This (supervised) wrapper method starts with the full model. RFE then uses the model’s feature importance (model weights, coefficients) to decide which feature to remove – recursively extracting features until the desired data table is reached. \n",
    "\n",
    "RFE fits the data to a specific model. Here we will look at feature selection in regard to Logistic Regression. Because of this model selection, our data is standardised beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2620d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def recursive_feature_elimination_LR(df):\n",
    "    # organise dataset into X (training examples) and y (targets)\n",
    "    featuresToDrop = ['Date', 'Match Outcome', 'Home Team', 'Away Team', 'Full Time Result']\n",
    "    assert set(featuresToDrop).issubset(df.columns), \"Some columns in featuresToDrop are missing in df\"\n",
    "    data = df.drop(featuresToDrop, axis=1)\n",
    "    target = df['Full Time Result']\n",
    "    \n",
    "    data = standardisation(data, terms=list(data.columns))\n",
    "    \n",
    "    # collect the feature names\n",
    "    feature_names = list(data.columns)\n",
    "        \n",
    "    # perform RFE\n",
    "    rfe = RFE(estimator=LogisticRegression(max_iter=500), n_features_to_select=number_of_components) # taken from PCA\n",
    "    rfe.fit(data, target)\n",
    "    \n",
    "    # get feature rankings and selected features\n",
    "    feature_ranking = rfe.ranking_\n",
    "    selected_features = [feature for feature, rank in zip(feature_names, feature_ranking) if rank == 1]\n",
    "    \n",
    "    print(\"Selected Features by RFE:\")\n",
    "    print(selected_features)\n",
    "    \n",
    "    # plot feature rankings\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sorted_features = sorted(zip(feature_names, feature_ranking), key=lambda x: x[1])\n",
    "    sorted_names, sorted_ranks = zip(*sorted_features)\n",
    "\n",
    "    # increase spacing between bars\n",
    "    y_positions = np.arange(len(sorted_names)) * 2\n",
    "    bar_height = 0.6\n",
    "\n",
    "    # generate gradient colors from blue to green\n",
    "    colors = [(0, 220/255, 1 - alpha) for alpha in np.linspace(0, 1, len(sorted_ranks))]\n",
    "\n",
    "    # plot horizontal bar chart with gradient colors\n",
    "    for ypos, rank, color in zip(y_positions, sorted_ranks, colors):\n",
    "        plt.barh(ypos, rank, height=bar_height, color=color)\n",
    "\n",
    "    plt.yticks(y_positions, sorted_names, fontsize=7)\n",
    "    plt.xlabel(\"RFE Ranking (1 = Selected)\", fontsize=12)\n",
    "    plt.ylabel(\"Features\", fontsize=12)\n",
    "    plt.title(\"Feature Importance and Selection by RFE\", fontsize=14)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return selected_features\n",
    "            \n",
    "    \n",
    "\n",
    "logistic_features = recursive_feature_elimination_LR(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21089915",
   "metadata": {},
   "source": [
    "Next is Recursive Feature Engineering for SVM. It will be a repeat of the last function, this time using a SVM model for feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a97cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94797ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec4a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26f918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ebffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def chronological_split(df, train_ratio=0.8, chronological=False):\n",
    "    df = df.sort_values(by='Date')\n",
    "    df.drop(columns=['Date'], inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    if chronological:\n",
    "        train_size = int(len(df) * train_ratio)\n",
    "        train_df = df[:train_size]\n",
    "        test_df = df[train_size:]\n",
    "    else:\n",
    "        train_df, test_df = train_test_split(df, train_size=train_ratio, random_state=31, shuffle=True)\n",
    "    return train_df, test_df\n",
    "\n",
    "def encode_teams(df, encoding=\"one-hot\"):\n",
    "    if encoding == \"one-hot\":\n",
    "        encoder = OneHotEncoder()\n",
    "        encoded_teams = encoder.fit_transform(df[['Home Team']]).toarray()\n",
    "        encoded_team_columns = encoder.get_feature_names_out(['Home Team'])\n",
    "        \n",
    "        encoded_df = pd.DataFrame(encoded_teams, columns=encoded_team_columns, index=df.index)\n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "        return df.drop(['Home Team'], axis=1)\n",
    "    else:\n",
    "        teams = df['Home Team'].unique()        \n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(teams)\n",
    "        \n",
    "        df['Home Team'] = encoder.transform(df['Home Team'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "def standardize_features(df, features, scale_type='minmax'):\n",
    "    if scale_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else: \n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b93643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import root_mean_squared_error, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class RecencyModelTrainingNew:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_with_iterations(self, X_train, y_train, X_test, y_test, iterations):\n",
    "        metrics = {\n",
    "            'train_accuracy': [], 'test_accuracy': [],\n",
    "            'train_rmse': [], 'test_rmse': [],\n",
    "            'train_precision': [], 'test_precision': [],\n",
    "            'train_recall': [], 'test_recall': [],\n",
    "            'train_f1': [], 'test_f1': []\n",
    "        }\n",
    "\n",
    "        for max_iter in iterations:\n",
    "            model = LogisticRegression(\n",
    "                multi_class='multinomial', solver='lbfgs', max_iter=max_iter,\n",
    "                random_state=31\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            train_predictions = model.predict(X_train)\n",
    "            test_predictions = model.predict(X_test)\n",
    "\n",
    "            self._compute_metrics(metrics, train_predictions, test_predictions, y_train, y_test)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def train_and_evaluate_knn(self, X_train, y_train, X_test, y_test, neighbors_range):\n",
    "        metrics = {\n",
    "            'train_accuracy': [], 'test_accuracy': [],\n",
    "            'train_rmse': [], 'test_rmse': [],\n",
    "            'train_precision': [], 'test_precision': [],\n",
    "            'train_recall': [], 'test_recall': [],\n",
    "            'train_f1': [], 'test_f1': []\n",
    "        }\n",
    "\n",
    "        for n_neighbors in neighbors_range:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "            knn.fit(X_train, y_train)\n",
    "\n",
    "            train_predictions = knn.predict(X_train)\n",
    "            test_predictions = knn.predict(X_test)\n",
    "\n",
    "            self._compute_metrics(metrics, train_predictions, test_predictions, y_train, y_test)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def train_and_evaluate_svm(self, X_train, y_train, X_test, y_test):\n",
    "        metrics = {\n",
    "            'train_accuracy': [], 'test_accuracy': [],\n",
    "            'train_rmse': [], 'test_rmse': [],\n",
    "            'train_precision': [], 'test_precision': [],\n",
    "            'train_recall': [], 'test_recall': [],\n",
    "            'train_f1': [], 'test_f1': []\n",
    "        }\n",
    "\n",
    "        svm = SVC(kernel='linear', random_state=31)\n",
    "        svm.fit(X_train, y_train)\n",
    "\n",
    "        train_predictions = svm.predict(X_train)\n",
    "        test_predictions = svm.predict(X_test)\n",
    "\n",
    "        self._compute_metrics(metrics, train_predictions, test_predictions, y_train, y_test)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "\n",
    "    def train_and_evaluate_lstm(self, X_train, y_train, X_test, y_test, epochs=10):\n",
    "        metrics = {\n",
    "            'train_accuracy': [], 'test_accuracy': [],\n",
    "            'train_rmse': [], 'test_rmse': [],\n",
    "            'train_precision': [], 'test_precision': [],\n",
    "            'train_recall': [], 'test_recall': [],\n",
    "            'train_f1': [], 'test_f1': []\n",
    "        }\n",
    "\n",
    "        # One-hot encode the target labels for multi-class classification\n",
    "        # Since target variable is int (0, 1, 2), we use to_categorical to one-hot encode it\n",
    "        y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
    "        y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "        # Reshape data for LSTM [samples, time steps, features]\n",
    "        X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        # Define the LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "            LSTM(64, return_sequences=False),\n",
    "            Dense(3, activation='softmax')  # For multi-class classification (3 classes)\n",
    "        ])\n",
    "        \n",
    "        # Compile the model with categorical crossentropy for multi-class classification\n",
    "        lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        lstm_model.fit(X_train, y_train_one_hot, epochs=epochs, batch_size=32, verbose=1)\n",
    "\n",
    "        # Predict probabilities for each class\n",
    "        train_predictions = lstm_model.predict(X_train)\n",
    "        test_predictions = lstm_model.predict(X_test)\n",
    "\n",
    "        # Convert probabilities to class predictions (0, 1, or 2)\n",
    "        train_predictions = train_predictions.argmax(axis=1)  # Select the class with the highest probability\n",
    "        test_predictions = test_predictions.argmax(axis=1)\n",
    "\n",
    "        # Compute metrics for multi-class classification\n",
    "        self._compute_metrics(metrics, train_predictions, test_predictions, y_train, y_test)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def _compute_metrics(self, metrics, train_predictions, test_predictions, y_train, y_test):\n",
    "        train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "        test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "        metrics['train_accuracy'].append(train_accuracy)\n",
    "        metrics['test_accuracy'].append(test_accuracy)\n",
    "\n",
    "        metrics['train_rmse'].append(np.sqrt(np.mean((y_train - train_predictions) ** 2)))\n",
    "        metrics['test_rmse'].append(np.sqrt(np.mean((y_test - test_predictions) ** 2)))\n",
    "\n",
    "        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(\n",
    "            y_train, train_predictions, average='weighted'\n",
    "        )\n",
    "        test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(\n",
    "            y_test, test_predictions, average='weighted'\n",
    "        )\n",
    "\n",
    "        metrics['train_precision'].append(train_precision)\n",
    "        metrics['test_precision'].append(test_precision)\n",
    "        metrics['train_recall'].append(train_recall)\n",
    "        metrics['test_recall'].append(test_recall)\n",
    "        metrics['train_f1'].append(train_f1)\n",
    "        metrics['test_f1'].append(test_f1)\n",
    "\n",
    "    def plot_metrics(self, metrics, model_name, iterations=None, neighbors_range=None):\n",
    "        metric_keys = list(metrics.keys())\n",
    "        n_metrics = len(metric_keys)\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, key in enumerate(metric_keys, 1):\n",
    "            plt.subplot((n_metrics + 1) // 2, 2, i)\n",
    "\n",
    "            # Print the metric data for debugging\n",
    "            print(f\"Plotting Metric: {key}\")\n",
    "            print(f\"Metric Data: {metrics[key]}\")  # Print the actual metrics data for inspection\n",
    "            \n",
    "            if iterations is not None:\n",
    "                print(f\"Iterations: {iterations}\")\n",
    "                # Ensure that iterations and metrics match in length\n",
    "                if len(metrics[key]) != len(iterations):\n",
    "                    print(f\"Warning: Length mismatch between iterations and {key} metric\")\n",
    "                plt.plot(iterations, metrics[key], label=key, marker='o')\n",
    "                x_vals = iterations\n",
    "            elif neighbors_range is not None:\n",
    "                print(f\"Neighbors Range: {neighbors_range}\")\n",
    "                # Ensure that neighbors_range and metrics match in length\n",
    "                if len(metrics[key]) != len(neighbors_range):\n",
    "                    print(f\"Warning: Length mismatch between neighbors_range and {key} metric\")\n",
    "                plt.plot(neighbors_range, metrics[key], label=key, marker='o')\n",
    "                x_vals = neighbors_range\n",
    "            else:\n",
    "                plt.plot(metrics[key], label=key, marker='o')\n",
    "                x_vals = range(len(metrics[key]))  # Default x-values if neither is provided\n",
    "\n",
    "            # Check if there are multiple values to plot\n",
    "            if len(x_vals) > 1:\n",
    "                for x, y in zip(x_vals, metrics[key]):\n",
    "                    plt.text(x, y, f'{y:.2f}', fontsize=8, ha='center', va='bottom')\n",
    "            else:\n",
    "                print(f\"Warning: Only one data point for {key}. This may indicate an issue with data collection.\")\n",
    "\n",
    "            plt.xlabel('Iterations' if iterations is not None else 'Number of Neighbors')\n",
    "            plt.ylabel(f'{key}')\n",
    "            plt.title(f'{model_name} - {key} over Iterations' if iterations is not None else f'{model_name} - {key} over Neighbors')\n",
    "            plt.grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        joblib.dump(self.model, filename)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        self.model = joblib.load(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Avg Goals Scored Home Last 1 Games',\n",
    "       'Avg Goals Scored Away Last 1 Games',\n",
    "       'Avg Goals Scored Home Last 2 Games',\n",
    "       'Avg Goals Scored Away Last 2 Games',\n",
    "       'Avg Goals Scored Home Last 3 Games',\n",
    "       'Avg Goals Scored Away Last 3 Games',\n",
    "       'Avg Goals Scored Home Last 4 Games',\n",
    "       'Avg Goals Scored Away Last 4 Games',\n",
    "       'Avg Goals Scored Home Last 5 Games',\n",
    "       'Avg Goals Scored Away Last 5 Games',\n",
    "       'Avg Goals Conceded Home Last 1 Games',\n",
    "       'Avg Goals Conceded Away Last 1 Games',\n",
    "       'Avg Goals Conceded Home Last 2 Games',\n",
    "       'Avg Goals Conceded Away Last 2 Games',\n",
    "       'Avg Goals Conceded Home Last 3 Games',\n",
    "       'Avg Goals Conceded Away Last 3 Games',\n",
    "       'Avg Goals Conceded Home Last 4 Games',\n",
    "       'Avg Goals Conceded Away Last 4 Games',\n",
    "       'Avg Goals Conceded Home Last 5 Games',\n",
    "       'Avg Goals Conceded Away Last 5 Games',\n",
    "       'Avg Attack Strength Home Last 1 Games',\n",
    "       'Avg Attack Strength Away Last 1 Games',\n",
    "       'Avg Attack Strength Home Last 2 Games',\n",
    "       'Avg Attack Strength Away Last 2 Games',\n",
    "       'Avg Attack Strength Home Last 3 Games',\n",
    "       'Avg Attack Strength Away Last 3 Games',\n",
    "       'Avg Attack Strength Home Last 4 Games',\n",
    "       'Avg Attack Strength Away Last 4 Games',\n",
    "       'Avg Attack Strength Home Last 5 Games',\n",
    "       'Avg Attack Strength Away Last 5 Games',\n",
    "       'Avg Midfield Strength Home Last 1 Games',\n",
    "       'Avg Midfield Strength Away Last 1 Games',\n",
    "       'Avg Midfield Strength Home Last 2 Games',\n",
    "       'Avg Midfield Strength Away Last 2 Games',\n",
    "       'Avg Midfield Strength Home Last 3 Games',\n",
    "       'Avg Midfield Strength Away Last 3 Games',\n",
    "       'Avg Midfield Strength Home Last 4 Games',\n",
    "       'Avg Midfield Strength Away Last 4 Games',\n",
    "       'Avg Midfield Strength Home Last 5 Games',\n",
    "       'Avg Midfield Strength Away Last 5 Games',\n",
    "       'Avg Defense Strength Home Last 1 Games',\n",
    "       'Avg Defense Strength Away Last 1 Games',\n",
    "       'Avg Defense Strength Home Last 2 Games',\n",
    "       'Avg Defense Strength Away Last 2 Games',\n",
    "       'Avg Defense Strength Home Last 3 Games',\n",
    "       'Avg Defense Strength Away Last 3 Games',\n",
    "       'Avg Defense Strength Home Last 4 Games',\n",
    "       'Avg Defense Strength Away Last 4 Games',\n",
    "       'Avg Defense Strength Home Last 5 Games',\n",
    "       'Avg Defense Strength Away Last 5 Games',\n",
    "       'Avg Recent Performance Home Last 1 Games',\n",
    "       'Avg Recent Performance Away Last 1 Games',\n",
    "       'Avg Recent Performance Home Last 2 Games',\n",
    "       'Avg Recent Performance Away Last 2 Games',\n",
    "       'Avg Recent Performance Home Last 3 Games',\n",
    "       'Avg Recent Performance Away Last 3 Games',\n",
    "       'Avg Recent Performance Home Last 4 Games',\n",
    "       'Avg Recent Performance Away Last 4 Games',\n",
    "       'Avg Recent Performance Home Last 5 Games',\n",
    "       'Avg Recent Performance Away Last 5 Games',\n",
    "       'Home Team',\n",
    "       'Match Outcome',\n",
    "       'Date'\n",
    "]\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c882b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Preprocessing Data...')\n",
    "df = encode_teams(df)\n",
    "numerical_features = [col for col in df.columns if 'Avg' in col]\n",
    "df = standardize_features(df, numerical_features)\n",
    "\n",
    "train_df, test_df = chronological_split(df)\n",
    "\n",
    "X_train, y_train = train_df.drop('Match Outcome', axis=1), train_df['Match Outcome']\n",
    "X_test, y_test = test_df.drop('Match Outcome', axis=1), test_df['Match Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c58e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "print('Starting Training...')\n",
    "trainer = RecencyModelTrainingNew()\n",
    "\n",
    "iterations = np.arange(0, 200, 10)\n",
    "neighbors_range = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51]\n",
    "\n",
    "metrics_logistic = trainer.train_with_iterations(X_train, y_train, X_test, y_test, iterations)\n",
    "metrics_knn = trainer.train_and_evaluate_knn(X_train, y_train, X_test, y_test, neighbors_range)\n",
    "metrics_svm = trainer.train_and_evaluate_svm(X_train, y_train, X_test, y_test)\n",
    "metrics_lstm = trainer.train_and_evaluate_lstm(X_train, y_train, X_test, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Metrics for all Models\n",
    "trainer.plot_metrics(metrics_logistic, \"Logistic Regression\", iterations=iterations)\n",
    "trainer.plot_metrics(metrics_knn, \"KNN\", neighbors_range=neighbors_range)\n",
    "trainer.plot_metrics(metrics_svm, \"SVM\")\n",
    "trainer.plot_metrics(metrics_lstm, \"LSTM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
